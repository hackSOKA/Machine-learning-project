{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSaeg9seutCc"
   },
   "source": [
    "# Trading Dataset: S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1543878731505,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "c3-PWoMuutCg",
    "outputId": "6e5b308a-dc44-459e-d529-243b1abe3af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1543878731702,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "G2lD1Us5u5Yt",
    "outputId": "81e87013-6263-44f1-b74d-1663bddc70f9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4be28ad9ce06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjuP_xUDutCu"
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1543878733960,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "mrjar8noutCy",
    "outputId": "94ff68c8-2490-42d0-8a0c-071f2f5cd10f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'drive/My Drive/Colab Notebooks/ML_project/dataset1.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-634012d03d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmydataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/Colab Notebooks/ML_project/dataset1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmydataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'drive/My Drive/Colab Notebooks/ML_project/dataset1.csv' does not exist"
     ]
    }
   ],
   "source": [
    "mydataset = pd.read_csv('drive/My Drive/Colab Notebooks/ML_project/dataset1.csv')\n",
    "spy = mydataset.iloc[:,:].values\n",
    "spy.shape[0]\n",
    "mydataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1543878734567,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "pgDFGxWyUo4Y",
    "outputId": "3b483932-d4e5-46d6-e01d-2bf27a96fec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000-02-08', 0.01577, 0.00949, ..., 0.0567, -0.001, 0],\n",
       "       ['2000-02-09', 0.01594, 0.01207, ..., 0.0576, -0.0013, -1],\n",
       "       ['2000-02-10', -0.00292, -0.007109999999999999, ..., 0.0579, 0.0,\n",
       "        0],\n",
       "       ...,\n",
       "       ['2018-11-07', 0.01938, 0.006809999999999999, ..., 0.0219, 0.0026,\n",
       "        1],\n",
       "       ['2018-11-08', 0.02278, 0.01455, ..., 0.0219, 0.0026, 0],\n",
       "       ['2018-11-09', 0.01438, 0.0094, ..., 0.022000000000000002, 0.0025,\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOMBLRklitD2"
   },
   "source": [
    "# Tuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZfYx7ICiw_k"
   },
   "outputs": [],
   "source": [
    "def log_tune_pred(x_train,y_train,x_test,y_test):\n",
    "  logistic = LogisticRegression()\n",
    "  parameter_logistic1 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[1e-4,1e-2,0.1,1,10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs'),\n",
    "                      'tol' : [1e-2,1] , 'max_iter' : [100,1000,10000]}\n",
    "\n",
    "  CV_logistic1 = GridSearchCV(logistic, parameter_logistic1, cv = 5)\n",
    "  CV_logistic1.fit(x_train, y_train.astype('float'))\n",
    "  predlog1 = CV_logistic1.predict(x_test)\n",
    "  acc = accuracy_score(y_test.astype(\"float\"),predlog1)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMfAZBDmqJBY"
   },
   "outputs": [],
   "source": [
    "def rf_tune_pred(x_train,y_train,x_test,y_test):\n",
    "  rfc = RandomForestClassifier()\n",
    "  parameter_rfc1 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "  CV_rfc1 = GridSearchCV(rfc, parameter_rfc1, cv = 5)\n",
    "  CV_rfc1.fit(x_train, y_train.astype('float'))\n",
    "  predrf = CV_rfc1.predict(x_test)\n",
    "  acc = accuracy_score(y_test.astype(\"float\"),predrf)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcRL1wOawFp-"
   },
   "source": [
    "# Splitting strategy 1 \n",
    "All records up to the split point are taken as the training dataset and all records from the split point to the end of the list of observations are taken as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbKA0A29wSNP"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(spy) * 0.9)\n",
    "train, test = spy[0:train_size], spy[train_size:len(spy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1543878736652,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "KAmMornswRxA",
    "outputId": "cdeb40dd-21cd-4f7f-aecc-4aadc7a984f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4252, 14)\n",
      "(473, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1543878737645,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "nJKt9cQaO0To",
    "outputId": "a43cd618-d4e5-4efa-9a97-1ea4da23695f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4252, 12)\n",
      "(4252,)\n",
      "(473, 12)\n",
      "(473,)\n"
     ]
    }
   ],
   "source": [
    "x_train=train[:,1:-1]\n",
    "print(x_train.shape)\n",
    "y_train = train[:,13]\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test=test[:,1:-1]\n",
    "print(x_test.shape)\n",
    "y_test = test[:,13]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwR7UZL34H-I"
   },
   "source": [
    "tester les algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJcOEqrvSAwE"
   },
   "source": [
    "# Splitting strategy 2\n",
    "Splitting the time series into train and test sets multiple times.\n",
    "\n",
    "Requires multiple models to be trained and evaluated, but this additional computational expense provides a more robust estimate of the expected performance of the chosen method and configuration on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIK4bSfZVSfR"
   },
   "outputs": [],
   "source": [
    "X=spy\n",
    "splits = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1532247,
     "status": "ok",
     "timestamp": 1543885995395,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "HLOTJrtvi6Ta",
    "outputId": "da900394-be99-4ef8-bf4f-978636e5a1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 1577\n",
      "Training Observations: 790\n",
      "Testing Observations: 787\n",
      "Observations: 2364\n",
      "Training Observations: 1577\n",
      "Testing Observations: 787\n",
      "Observations: 3151\n",
      "Training Observations: 2364\n",
      "Testing Observations: 787\n",
      "Observations: 3938\n",
      "Training Observations: 3151\n",
      "Testing Observations: 787\n",
      "Observations: 4725\n",
      "Training Observations: 3938\n",
      "Testing Observations: 787\n",
      "Mean accuracy Logistic: 0.524269377382465\n",
      "Mean accuracy Random Forest: 0.5143583227445998\n"
     ]
    }
   ],
   "source": [
    "accuracies_log = []\n",
    "accuracies_rf = []\n",
    "for train_index,test_index in splits.split(X):\n",
    "  ## split data\n",
    "  train = X[train_index]\n",
    "  x_train = train[:,1:-1]\n",
    "  y_train = train[:,-1]\n",
    "  \n",
    "  test = X[test_index]\n",
    "  x_test = test[:,1:-1]\n",
    "  y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "  accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_log.append(accu_log)\n",
    "  \n",
    "  accu_rf = rf_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_rf.append(accu_rf)\n",
    "  \n",
    "  print('Observations: %d' % (len(train) + len(test)))\n",
    "  print('Training Observations: %d' % (len(train)))\n",
    "  print('Testing Observations: %d' % (len(test)))\n",
    "  \n",
    "  \n",
    "#print(\"Accuracy for Logistic Regression second splitting strategy: \",accuracies)\n",
    "print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))\n",
    "print(\"Mean accuracy Random Forest:\",  np.mean(accuracies_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1543886133505,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "kJ5wczb2fFbx",
    "outputId": "15c45c30-d484-47e0-dc82-5b3f591c2730"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracies_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8405bd716dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"split 1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split 2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split 3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'split 4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'split 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracies_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logistic regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracies_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"random forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_rf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracies_log' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"split 1\",\"split 2\",\"split 3\",'split 4','split 5']  \n",
    "plt.figure(figsize = (10,8))\n",
    "plot_log, = plt.plot(labels,accuracies_log,label=\"logistic regression\")\n",
    "plot_rf, = plt.plot(labels,accuracies_rf, label = \"random forest\")\n",
    "plt.legend(handles=[plot_log,plot_rf],loc=1)\n",
    "plt.title(\"Logistic regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEWikKUi0Qyg"
   },
   "source": [
    "# Splitting strategy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOMgM3XI5Z4Q"
   },
   "outputs": [],
   "source": [
    "n_train = 4000\n",
    "n_records = len(X)\n",
    "accuracies_log_st2 = []\n",
    "for i in range(n_train, n_records):\n",
    "  train = X[0:i]\n",
    "  test = X[i:i+1]\n",
    "  x_train = train[:,1:-1]\n",
    "  y_train = train[:,-1]\n",
    "  x_test = test[:,1:-1]\n",
    "  y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "  accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_log_st2.append(accu_log)\n",
    "  \n",
    "print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 473,
     "status": "error",
     "timestamp": 1543888008211,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "NqNPmMRK0WWb",
    "outputId": "151a6b33-e012-4751-cfbe-419f26fc89d6"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-dd1f9e51e8ff>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    x_train = train[:,1:-1]\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "n_train = 4242\n",
    "n_records = len(X)\n",
    "accuracies_log_st2 = []\n",
    "for i in range(n_train, n_records):\n",
    "\ttrain, test = X[0:i], X[i:i+1]\n",
    "  x_train = train[:,1:-1]\n",
    "  y_train = train[:,-1]\n",
    "  x_test = test[:,1:-1]\n",
    "  y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "  accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_log_st2.append(accu_log)\n",
    "  \n",
    "  print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))\n",
    "\t#print('train=%d, test=%d' % (len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmZ9NDxTutDQ"
   },
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UppsFZnUutDS",
    "outputId": "d081acb4-4528-4e0c-d864-dbc819227be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 train feature shape: (1380, 12)\n",
      "FOLD 1 train output shape: (1380,)\n",
      "FOLD 1 test feature shape: (1380, 12)\n",
      "FOLD 1 test output shape: (1380,)\n",
      "FOLD 2 train feature shape: (2180, 12)\n",
      "FOLD 2 train output shape: (2180,)\n",
      "FOLD 2 test feature shape: (2180, 12)\n",
      "FOLD 2 test output shape: (2180,)\n",
      "FOLD 3 train feature shape: (2980, 12)\n",
      "FOLD 3 train output shape: (2980,)\n",
      "FOLD 3 test feature shape: (2980, 12)\n",
      "FOLD 3 test output shape: (2980,)\n",
      "FOLD 4 train feature shape: (3780, 12)\n",
      "FOLD 4 train output shape: (3780,)\n",
      "FOLD 4 test feature shape: (3780, 12)\n",
      "FOLD 4 test output shape: (3780,)\n"
     ]
    }
   ],
   "source": [
    "#4-FOLD FORWARD CHAINING\n",
    "#70% train, 30% validation\n",
    "#https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "#https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#FOLD 1\n",
    "x1 = features[0:1725,:]\n",
    "y1 = output[0:1725]\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.20, train_size=0.80)\n",
    "x_train1 = x_train1.astype('float')\n",
    "y_train1 = y_train1.astype('int')\n",
    "x_test1 = x_train1.astype('float')\n",
    "y_test1 = y_train1.astype('int')\n",
    "print('FOLD 1 train feature shape:',x_train1.shape)\n",
    "print('FOLD 1 train output shape:',y_train1.shape)\n",
    "print('FOLD 1 test feature shape:',x_test1.shape)\n",
    "print('FOLD 1 test output shape:',y_test1.shape)\n",
    "\n",
    "\n",
    "#FOLD 2\n",
    "x2 = features[0:2725,:]\n",
    "y2 = output[0:2725]\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.20, train_size=0.80)\n",
    "x_train2 = x_train2.astype('float')\n",
    "y_train2 = y_train2.astype('int')\n",
    "x_test2 = x_train2.astype('float')\n",
    "y_test2 = y_train2.astype('int')\n",
    "print('FOLD 2 train feature shape:',x_train2.shape)\n",
    "print('FOLD 2 train output shape:',y_train2.shape)\n",
    "print('FOLD 2 test feature shape:',x_test2.shape)\n",
    "print('FOLD 2 test output shape:',y_test2.shape)\n",
    "\n",
    "\n",
    "#FOLD 3\n",
    "x3 = features[0:3725,:]\n",
    "y3 = output[0:3725]\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.20, train_size=0.80)\n",
    "x_train3 = x_train3.astype('float')\n",
    "y_train3 = y_train3.astype('int')\n",
    "x_test3 = x_train3.astype('float')\n",
    "y_test3 = y_train3.astype('int')\n",
    "print('FOLD 3 train feature shape:',x_train3.shape)\n",
    "print('FOLD 3 train output shape:',y_train3.shape)\n",
    "print('FOLD 3 test feature shape:',x_test3.shape)\n",
    "print('FOLD 3 test output shape:',y_test3.shape)\n",
    "\n",
    "\n",
    "#FOLD 4\n",
    "x4 = features[0:4725,:]\n",
    "y4 = output[0:4725]\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size=0.20, train_size=0.80)\n",
    "x_train4 = x_train4.astype('float')\n",
    "y_train4 = y_train4.astype('int')\n",
    "x_test4 = x_train4.astype('float')\n",
    "y_test4 = y_train4.astype('int')\n",
    "print('FOLD 4 train feature shape:',x_train4.shape)\n",
    "print('FOLD 4 train output shape:',y_train4.shape)\n",
    "print('FOLD 4 test feature shape:',x_test4.shape)\n",
    "print('FOLD 4 test output shape:',y_test4.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ManwUNoLutDe"
   },
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lWPIWvzutDg",
    "outputId": "980a15a9-2cbe-4482-c731-004b899942a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random forest 1:  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'log2', 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test accuracy for Random Forest on FOLD 1:  0.6224637681159421\n",
      "Best parameters for Random forest 2:  {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'auto', 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test accuracy for Random Forest on FOLD 2:  0.631651376146789\n",
      "Best parameters for Random forest 3:  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'auto', 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test accuracy for Random Forest on FOLD 3:  0.5956375838926175\n",
      "Best parameters for Random forest 4:  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 200}\n",
      "Accuracy for Random Forest on FOLD 4:  0.6476190476190476\n",
      "Average accuracy on test set: 0.624342943943599\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#FOLD1\n",
    "parameter_rfc1 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc1 = GridSearchCV(rfc, parameter_rfc1, cv = 5)\n",
    "CV_rfc1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for Random forest 1: \",CV_rfc1.best_params_)\n",
    "\n",
    "rfc1 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 20,\n",
    "                              n_estimators = 200)\n",
    "rfc1.fit(x_train1, y_train1)\n",
    "predrfc1 = rfc1.predict(x_test1)\n",
    "print(\"Test accuracy for Random Forest on FOLD 1: \",accuracy_score(y_test1,predrfc1))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_rfc2 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc2 = GridSearchCV(rfc, parameter_rfc2, cv = 5)\n",
    "CV_rfc2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for Random forest 2: \",CV_rfc2.best_params_)\n",
    "\n",
    "rfc2 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 200)\n",
    "rfc2.fit(x_train2, y_train2)\n",
    "predrfc2 = rfc2.predict(x_test2)\n",
    "print(\"Test accuracy for Random Forest on FOLD 2: \",accuracy_score(y_test2,predrfc2))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD3\n",
    "parameter_rfc3 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc3 = GridSearchCV(rfc, parameter_rfc3, cv = 5)\n",
    "CV_rfc3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for Random forest 3: \",CV_rfc3.best_params_)\n",
    "\n",
    "rfc3 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 10)\n",
    "rfc3.fit(x_train3, y_train3)\n",
    "predrfc3 = rfc3.predict(x_test3)\n",
    "print(\"Test accuracy for Random Forest on FOLD 3: \",accuracy_score(y_test3,predrfc3))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD4\n",
    "parameter_rfc4 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "CV_rfc4 = GridSearchCV(rfc, parameter_rfc4, cv = 5)\n",
    "CV_rfc4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for Random forest 4: \",CV_rfc4.best_params_)\n",
    "\n",
    "rfc4 = RandomForestClassifier(criterion = 'entropy',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 200)\n",
    "rfc4.fit(x_train4, y_train4)\n",
    "predrfc4 = rfc4.predict(x_test4)\n",
    "print(\"Accuracy for Random Forest on FOLD 4: \",accuracy_score(y_test4,predrfc4))\n",
    "\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predrfc1),accuracy_score(y_test2,predrfc2), accuracy_score(y_test3,predrfc3), accuracy_score(y_test4,predrfc4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I73DX1ahutD1"
   },
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZ_wseVvutD6",
    "outputId": "e9a7200f-12fd-4fe6-dd1f-8b33de6f8979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression 1:  {'C': 10, 'solver': 'sag', 'tol': 0.01}\n",
      "Accuracy for Logistic Regression on FOLD 1:  0.4855072463768116\n",
      "Best parameters for Logistic Regression 2:  {'C': 10, 'solver': 'newton-cg', 'tol': 0.01}\n",
      "Accuracy for Logistic Regression on FOLD 2:  0.47706422018348627\n",
      "Best parameters for Logistic Regression 3:  {'C': 10, 'solver': 'newton-cg', 'tol': 1e-05}\n",
      "Accuracy for Logistic Regression on FOLD 3:  0.5191275167785235\n",
      "Best parameters for Logistic Regression 4:  {'C': 10, 'solver': 'newton-cg', 'tol': 1e-05}\n",
      "Accuracy for Logistic Regression on FOLD 4:  0.5574074074074075\n",
      "Average accuracy on test set: 0.5097765976865571\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "#FOLD1\n",
    "parameter_logistic1 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic1 = GridSearchCV(logistic, parameter_logistic1, cv = 5)\n",
    "CV_logistic1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for Logistic Regression 1: \", CV_logistic1.best_params_)\n",
    "\n",
    "logistic1 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic1.fit(x_train1, y_train1)\n",
    "predlog1 = logistic1.predict(x_test1)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 1: \",accuracy_score(y_test1,predlog1))\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_logistic2 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic2 = GridSearchCV(logistic, parameter_logistic2, cv = 5)\n",
    "CV_logistic2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for Logistic Regression 2: \", CV_logistic2.best_params_)\n",
    "\n",
    "logistic2 = LogisticRegression(C = 10, solver = 'sag', tol = 0.01)\n",
    "logistic2.fit(x_train2, y_train2)\n",
    "predlog2 = logistic2.predict(x_test2)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 2: \",accuracy_score(y_test2,predlog2))\n",
    "\n",
    "#FOLD3\n",
    "parameter_logistic3 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic3 = GridSearchCV(logistic, parameter_logistic3, cv = 5)\n",
    "CV_logistic3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for Logistic Regression 3: \", CV_logistic3.best_params_)\n",
    "\n",
    "logistic3 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic3.fit(x_train3, y_train3)\n",
    "predlog3 = logistic3.predict(x_test3)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 3: \",accuracy_score(y_test3,predlog3))\n",
    "\n",
    "\n",
    "#FOLD4\n",
    "parameter_logistic4 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "CV_logistic4 = GridSearchCV(logistic, parameter_logistic4, cv = 5)\n",
    "CV_logistic4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for Logistic Regression 4: \", CV_logistic4.best_params_)\n",
    "\n",
    "logistic4 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic4.fit(x_train4, y_train4)\n",
    "predlog4 = logistic4.predict(x_test4)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 4: \",accuracy_score(y_test4,predlog4))\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predlog1),accuracy_score(y_test2,predlog2), accuracy_score(y_test3,predlog3), accuracy_score(y_test4,predlog4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLFbZVqnutEF"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z4BHdc-utEH",
    "outputId": "67ef4572-dd75-4f2b-a58d-424c7e9523f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM1:  {'C': 10, 'gamma': 0.9, 'kernel': 'rbf'}\n",
      "Best score for SVM1:  0.46304347826086956\n",
      "Accuracy for SVM on FOLD 1:  0.46159420289855074\n",
      "Best parameters for SVM2:  {'C': 10, 'kernel': 'linear'}\n",
      "Accuracy for SVM on FOLD 2:  0.4701834862385321\n",
      "Best parameters for SVM3:  {'C': 10, 'kernel': 'linear'}\n",
      "Accuracy for SVM on FOLD 3:  0.5130872483221477\n",
      "Best parameters for SVM4:  {'C': 1, 'kernel': 'linear'}\n",
      "Accuracy for SVM on FOLD 4:  0.5465608465608466\n",
      "Average accuracy on test set: 0.4978564460050193\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "\n",
    "#FOLD1\n",
    "parameter_svm1 = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), \n",
    "                  'C':[0.1, 10],\n",
    "                  'gamma':[0.01,0.9]}\n",
    "\n",
    "CV_svm1 = GridSearchCV(svm, parameter_svm1, cv = 2)\n",
    "CV_svm1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for SVM1: \", CV_svm1.best_params_)\n",
    "print(\"Best score for SVM1: \", CV_svm1.best_score_)\n",
    "\n",
    "svm1 = SVC(C = 0.1, kernel = 'rbf', gamma = 0.9, decision_function_shape = 'ovo')\n",
    "svm1.fit(x_train1, y_train1)\n",
    "predsvm1 = svm1.predict(x_test1)\n",
    "print(\"Accuracy for SVM on FOLD 1: \",accuracy_score(y_test1,predsvm1))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_svm2 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[0.1, 10]}\n",
    "\n",
    "CV_svm2 = GridSearchCV(svm, parameter_svm2, cv = 5)\n",
    "CV_svm2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for SVM2: \", CV_svm2.best_params_)\n",
    "\n",
    "svm2 = SVC(C = 10, kernel = 'linear')\n",
    "svm2.fit(x_train2, y_train2)\n",
    "predsvm2 = svm2.predict(x_test2)\n",
    "print(\"Accuracy for SVM on FOLD 2: \",accuracy_score(y_test2,predsvm2))\n",
    "\n",
    "#FOLD3\n",
    "parameter_svm3 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[1, 10]}\n",
    "\n",
    "CV_svm3 = GridSearchCV(svm, parameter_svm3, cv = 5)\n",
    "CV_svm3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for SVM3: \", CV_svm3.best_params_)\n",
    "\n",
    "svm3 = SVC(C = 1, kernel = 'linear')\n",
    "svm3.fit(x_train3, y_train3)\n",
    "predsvm3 = svm2.predict(x_test3)\n",
    "print(\"Accuracy for SVM on FOLD 3: \",accuracy_score(y_test3,predsvm3))\n",
    "\n",
    "#FOLD4\n",
    "parameter_svm4 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[1, 10]}\n",
    "\n",
    "CV_svm4 = GridSearchCV(svm, parameter_svm4, cv = 5)\n",
    "CV_svm4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for SVM4: \", CV_svm4.best_params_)\n",
    "\n",
    "svm4 = SVC(C = 1, kernel = 'linear')\n",
    "svm4.fit(x_train4, y_train4)\n",
    "predsvm4 = svm4.predict(x_test4)\n",
    "print(\"Accuracy for SVM on FOLD 4: \",accuracy_score(y_test4,predsvm4))\n",
    "\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predsvm1),accuracy_score(y_test2,predsvm2), accuracy_score(y_test3,predsvm3), accuracy_score(y_test4,predsvm4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLNjSlMrutEP"
   },
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xckIXHMWutER"
   },
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#FOLD1\n",
    "#parameter_NN1 = {'hidden_layer_sizes':[1, 10],'activation':('identity', 'relu','logistic', 'tanh'),\n",
    "                # 'solver':('lbfgs', 'sgd', 'adam'), 'alpha':[0.00001,0.01], 'batch_size':[10,100],\n",
    "                #'learning_rate':('constant','invscaling','adaptive'), 'learning_rate_init':[0.00001,0.01],\n",
    "                # 'tol':[0.000001,0.01]}\n",
    "#NN1_train = MLPClassifier()\n",
    "#NN1_train.fit(x_train1, y_train1)\n",
    "#NN1_valid = GridSearchCV(NN1_train, parameter_NN1)\n",
    "#NN1_valid.fit(x_valid1, y_valid1)\n",
    "#SVM1_valid.fit(x_train1, y_train1)\n",
    "#print(NN1_valid.best_params_)\n",
    "#NN1_score_train1 = NN1_train.score(x_train1, y_train1)\n",
    "#NN1_score_valid1 = NN1_valid.score(x_valid1, y_valid1)\n",
    "#NN1_score_test1 = NN1_valid.score(x_test1, y_test1)\n",
    "#print('Accuracy on the training set 1: {:.3f}'.format(NN1_score_train1))\n",
    "#print('Accuracy on the validation set 1: {:.3f}'.format(NN1_score_valid1))\n",
    "#print('Accuracy on the test set 1: {:.3f}'.format(NN1_score_test1))\n",
    "#print(NN1.predict(x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HN3pKGVxutEZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TRADING_v2_Selma.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
