{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSaeg9seutCc"
   },
   "source": [
    "# Trading Dataset: S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1543878731505,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "c3-PWoMuutCg",
    "outputId": "6e5b308a-dc44-459e-d529-243b1abe3af0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0315cc576885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjuP_xUDutCu"
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1543878733960,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "mrjar8noutCy",
    "outputId": "94ff68c8-2490-42d0-8a0c-071f2f5cd10f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>EMA10</th>\n",
       "      <th>EMA25</th>\n",
       "      <th>USD/JPY</th>\n",
       "      <th>USD/EUR</th>\n",
       "      <th>USD/GBP</th>\n",
       "      <th>USD/HKD</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>OIL</th>\n",
       "      <th>UK rate</th>\n",
       "      <th>Euro rate</th>\n",
       "      <th>FFR</th>\n",
       "      <th>T10Y-T2Y</th>\n",
       "      <th>OUPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-08</td>\n",
       "      <td>0.01577</td>\n",
       "      <td>0.00949</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>-0.00662</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-09</td>\n",
       "      <td>0.01594</td>\n",
       "      <td>0.01207</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>-0.00048</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.01404</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-02-10</td>\n",
       "      <td>-0.00292</td>\n",
       "      <td>-0.00711</td>\n",
       "      <td>-0.00064</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>-0.00500</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>0.00591</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-02-11</td>\n",
       "      <td>-0.00077</td>\n",
       "      <td>-0.00499</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>-0.00788</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-02-14</td>\n",
       "      <td>-0.01115</td>\n",
       "      <td>-0.01739</td>\n",
       "      <td>-0.00230</td>\n",
       "      <td>-0.00030</td>\n",
       "      <td>-0.00335</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00032</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    EMA10    EMA25  USD/JPY  USD/EUR  USD/GBP  USD/HKD     GOLD  \\\n",
       "0  2000-02-08  0.01577  0.00949  0.00074  0.00059  0.01084  0.00008 -0.00662   \n",
       "1  2000-02-09  0.01594  0.01207  0.00027  0.00030 -0.00048  0.00003  0.01404   \n",
       "2  2000-02-10 -0.00292 -0.00711 -0.00064  0.00099 -0.00500  0.00005 -0.00588   \n",
       "3  2000-02-11 -0.00077 -0.00499  0.00046  0.00020 -0.00788  0.00008  0.00696   \n",
       "4  2000-02-14 -0.01115 -0.01739 -0.00230 -0.00030 -0.00335  0.00005  0.00032   \n",
       "\n",
       "       OIL  UK rate  Euro rate     FFR  T10Y-T2Y  OUPUT  \n",
       "0  0.00035   0.0575     0.0225  0.0567   -0.0010      0  \n",
       "1  0.00071   0.0575     0.0225  0.0576   -0.0013     -1  \n",
       "2  0.00591   0.0600     0.0225  0.0579    0.0000      0  \n",
       "3  0.00034   0.0600     0.0225  0.0571   -0.0002     -1  \n",
       "4  0.00000   0.0600     0.0225  0.0579   -0.0006      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydataset = pd.read_csv('dataset1.csv')\n",
    "spy = mydataset.iloc[:,:].values\n",
    "spy.shape[0]\n",
    "mydataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1543878734567,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "pgDFGxWyUo4Y",
    "outputId": "3b483932-d4e5-46d6-e01d-2bf27a96fec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000-02-08', 0.01577, 0.00949, ..., 0.0567, -0.001, 0],\n",
       "       ['2000-02-09', 0.01594, 0.01207, ..., 0.0576, -0.0013, -1],\n",
       "       ['2000-02-10', -0.00292, -0.007109999999999999, ..., 0.0579, 0.0,\n",
       "        0],\n",
       "       ...,\n",
       "       ['2018-11-07', 0.01938, 0.006809999999999999, ..., 0.0219, 0.0026,\n",
       "        1],\n",
       "       ['2018-11-08', 0.02278, 0.01455, ..., 0.0219, 0.0026, 0],\n",
       "       ['2018-11-09', 0.01438, 0.0094, ..., 0.022000000000000002, 0.0025,\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOMBLRklitD2"
   },
   "source": [
    "# Tuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZfYx7ICiw_k"
   },
   "outputs": [],
   "source": [
    "def log_tune_pred(x_train,y_train,x_test,y_test):\n",
    "  logistic = LogisticRegression()\n",
    "  parameter_logistic1 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[1e-4,1e-2,0.1,1,10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs'),\n",
    "                      'tol' : [1e-2,1] , 'max_iter' : [100,1000,10000]}\n",
    "\n",
    "  CV_logistic1 = GridSearchCV(logistic, parameter_logistic1, cv = 5)\n",
    "  CV_logistic1.fit(x_train, y_train.astype('float'))\n",
    "  predlog1 = CV_logistic1.predict(x_test)\n",
    "  acc = accuracy_score(y_test.astype(\"float\"),predlog1)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMfAZBDmqJBY"
   },
   "outputs": [],
   "source": [
    "def rf_tune_pred(x_train,y_train,x_test,y_test):\n",
    "  rfc = RandomForestClassifier()\n",
    "  parameter_rfc1 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "  CV_rfc1 = GridSearchCV(rfc, parameter_rfc1, cv = 5)\n",
    "  CV_rfc1.fit(x_train, y_train.astype('float'))\n",
    "  predrf = CV_rfc1.predict(x_test)\n",
    "  acc = accuracy_score(y_test.astype(\"float\"),predrf)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_tune_pred(x_train,y_train,x_test,y_test):\n",
    "  svm = SVC()\n",
    "  parameter_svm1 = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), \n",
    "                  'C':[0.1, 10],\n",
    "                  'gamma':[0.01,0.9]}\n",
    "\n",
    "  CV_svm1 = GridSearchCV(svm, parameter_svm1, cv = 5)\n",
    "  CV_svm1.fit(x_train, y_train.astype('float'))\n",
    "  predsvm1 = CV_svm1.predict(x_test)\n",
    "  acc = accuracy_score(y_test.astype(\"float\"),predsvm1)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcRL1wOawFp-"
   },
   "source": [
    "# Splitting strategy 1 \n",
    "All records up to the split point are taken as the training dataset and all records from the split point to the end of the list of observations are taken as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbKA0A29wSNP"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(spy) * 0.9)\n",
    "train, test = spy[0:train_size], spy[train_size:len(spy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1543878736652,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "KAmMornswRxA",
    "outputId": "cdeb40dd-21cd-4f7f-aecc-4aadc7a984f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4252, 14)\n",
      "(473, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1543878737645,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "nJKt9cQaO0To",
    "outputId": "a43cd618-d4e5-4efa-9a97-1ea4da23695f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4252, 12)\n",
      "(4252,)\n",
      "(473, 12)\n",
      "(473,)\n"
     ]
    }
   ],
   "source": [
    "x_train=train[:,1:-1]\n",
    "print(x_train.shape)\n",
    "y_train = train[:,13]\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test=test[:,1:-1]\n",
    "print(x_test.shape)\n",
    "y_test = test[:,13]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 4725\n",
      "Training Observations: 4252\n",
      "Testing Observations: 473\n",
      "Accuracy Logistic: 0.7780126849894292\n",
      "Accuracy Random Forest: 0.7758985200845666\n",
      "Accuracy SVM: 0.7758985200845666\n"
     ]
    }
   ],
   "source": [
    " ## evaluate models\n",
    "accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "accu_rf = rf_tune_pred(x_train,y_train,x_test,y_test)\n",
    "accu_svm = svm_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  \n",
    "print('Observations: %d' % (len(train) + len(test)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))\n",
    "  \n",
    "print(\"Accuracy Logistic:\", accu_log)\n",
    "print(\"Accuracy Random Forest:\",  accu_rf)\n",
    "print(\"Accuracy SVM:\",  accu_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJcOEqrvSAwE"
   },
   "source": [
    "# Splitting strategy 2\n",
    "Splitting the time series into train and test sets multiple times.\n",
    "\n",
    "Requires multiple models to be trained and evaluated, but this additional computational expense provides a more robust estimate of the expected performance of the chosen method and configuration on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIK4bSfZVSfR"
   },
   "outputs": [],
   "source": [
    "X=spy\n",
    "splits = TimeSeriesSplit(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1532247,
     "status": "ok",
     "timestamp": 1543885995395,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "HLOTJrtvi6Ta",
    "outputId": "da900394-be99-4ef8-bf4f-978636e5a1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 4725\n",
      "Training Observations: 3780\n",
      "Testing Observations: 945\n",
      "Mean accuracy Logistic: 0.7111111111111111\n",
      "Mean accuracy Random Forest: 0.7153439153439154\n",
      "Mean accuracy SVM: 0.7153439153439154\n"
     ]
    }
   ],
   "source": [
    "accuracies_log = []\n",
    "accuracies_rf = []\n",
    "accuracies_svm = []\n",
    "for train_index,test_index in splits.split(X):\n",
    "  ## split data\n",
    "    train = X[train_index]\n",
    "    x_train = train[:,1:-1]\n",
    "    y_train = train[:,-1]\n",
    "  \n",
    "    test = X[test_index]\n",
    "    x_test = test[:,1:-1]\n",
    "    y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "accuracies_log.append(accu_log)\n",
    "  \n",
    "accu_rf = rf_tune_pred(x_train,y_train,x_test,y_test)\n",
    "accuracies_rf.append(accu_rf)\n",
    "  \n",
    "accu_svm = svm_tune_pred(x_train,y_train,x_test,y_test)\n",
    "accuracies_svm.append(accu_svm)\n",
    "    \n",
    "print('Observations: %d' % (len(train) + len(test)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))\n",
    "  \n",
    "#print(\"Accuracy for Logistic Regression second splitting strategy: \",accuracies)\n",
    "print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))\n",
    "print(\"Mean accuracy Random Forest:\",  np.mean(accuracies_rf))\n",
    "print(\"Mean accuracy SVM:\",  np.mean(accuracies_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1543886133505,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "kJ5wczb2fFbx",
    "outputId": "15c45c30-d484-47e0-dc82-5b3f591c2730"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8405bd716dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"split 1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split 2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split 3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'split 4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'split 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracies_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logistic regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracies_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"random forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_rf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"split 1\",\"split 2\",\"split 3\",'split 4','split 5']  \n",
    "plt.figure(figsize = (10,8))\n",
    "plot_log, = plt.plot(labels,accuracies_log,label=\"logistic regression\")\n",
    "plot_rf, = plt.plot(labels,accuracies_rf, label = \"random forest\")\n",
    "plt.legend(handles=[plot_log,plot_rf],loc=1)\n",
    "plt.title(\"Logistic regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEWikKUi0Qyg"
   },
   "source": [
    "# Splitting strategy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOMgM3XI5Z4Q"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3e80566d26d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m## evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0maccu_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_tune_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0maccuracies_log_st2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccu_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-167102edd836>\u001b[0m in \u001b[0;36mlog_tune_pred\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mCV_logistic1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_logistic1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mCV_logistic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mpredlog1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_logistic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredlog1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1291\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                     iprint=(verbose > 0) - 1, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0;31m# old scipy doesn't have maxiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_train = 4000\n",
    "n_records = len(X)\n",
    "accuracies_log_st2 = []\n",
    "for i in range(n_train, n_records):\n",
    "  train = X[0:i]\n",
    "  test = X[i:i+1]\n",
    "  x_train = train[:,1:-1]\n",
    "  y_train = train[:,-1]\n",
    "  x_test = test[:,1:-1]\n",
    "  y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "  accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_log_st2.append(accu_log)\n",
    "  \n",
    "print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 473,
     "status": "error",
     "timestamp": 1543888008211,
     "user": {
      "displayName": "Selma Skiredj",
      "photoUrl": "https://lh6.googleusercontent.com/-WFFwI0QwJio/AAAAAAAAAAI/AAAAAAAADV4/stHqXrhPfnM/s64/photo.jpg",
      "userId": "11368221759662114306"
     },
     "user_tz": 300
    },
    "id": "NqNPmMRK0WWb",
    "outputId": "151a6b33-e012-4751-cfbe-419f26fc89d6"
   },
   "outputs": [],
   "source": [
    "n_train = 4242\n",
    "n_records = len(X)\n",
    "accuracies_log_st2 = []\n",
    "for i in range(n_train, n_records):\n",
    "\ttrain, test = X[0:i], X[i:i+1]\n",
    "  x_train = train[:,1:-1]\n",
    "  y_train = train[:,-1]\n",
    "  x_test = test[:,1:-1]\n",
    "  y_test = test[:,-1]\n",
    "  \n",
    "  ## evaluate models\n",
    "  accu_log = log_tune_pred(x_train,y_train,x_test,y_test)\n",
    "  accuracies_log_st2.append(accu_log)\n",
    "  \n",
    "  print(\"Mean accuracy Logistic:\",  np.mean(accuracies_log))\n",
    "\t#print('train=%d, test=%d' % (len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmZ9NDxTutDQ"
   },
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UppsFZnUutDS",
    "outputId": "d081acb4-4528-4e0c-d864-dbc819227be6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-60d12588fe1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#FOLD 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1725\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1725\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "#4-FOLD FORWARD CHAINING\n",
    "#70% train, 30% validation\n",
    "#https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "#https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#FOLD 1\n",
    "x1 = features[0:1725,:]\n",
    "y1 = output[0:1725]\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.20, train_size=0.80)\n",
    "x_train1 = x_train1.astype('float')\n",
    "y_train1 = y_train1.astype('int')\n",
    "x_test1 = x_train1.astype('float')\n",
    "y_test1 = y_train1.astype('int')\n",
    "print('FOLD 1 train feature shape:',x_train1.shape)\n",
    "print('FOLD 1 train output shape:',y_train1.shape)\n",
    "print('FOLD 1 test feature shape:',x_test1.shape)\n",
    "print('FOLD 1 test output shape:',y_test1.shape)\n",
    "\n",
    "\n",
    "#FOLD 2\n",
    "x2 = features[0:2725,:]\n",
    "y2 = output[0:2725]\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.20, train_size=0.80)\n",
    "x_train2 = x_train2.astype('float')\n",
    "y_train2 = y_train2.astype('int')\n",
    "x_test2 = x_train2.astype('float')\n",
    "y_test2 = y_train2.astype('int')\n",
    "print('FOLD 2 train feature shape:',x_train2.shape)\n",
    "print('FOLD 2 train output shape:',y_train2.shape)\n",
    "print('FOLD 2 test feature shape:',x_test2.shape)\n",
    "print('FOLD 2 test output shape:',y_test2.shape)\n",
    "\n",
    "\n",
    "#FOLD 3\n",
    "x3 = features[0:3725,:]\n",
    "y3 = output[0:3725]\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.20, train_size=0.80)\n",
    "x_train3 = x_train3.astype('float')\n",
    "y_train3 = y_train3.astype('int')\n",
    "x_test3 = x_train3.astype('float')\n",
    "y_test3 = y_train3.astype('int')\n",
    "print('FOLD 3 train feature shape:',x_train3.shape)\n",
    "print('FOLD 3 train output shape:',y_train3.shape)\n",
    "print('FOLD 3 test feature shape:',x_test3.shape)\n",
    "print('FOLD 3 test output shape:',y_test3.shape)\n",
    "\n",
    "\n",
    "#FOLD 4\n",
    "x4 = features[0:4725,:]\n",
    "y4 = output[0:4725]\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size=0.20, train_size=0.80)\n",
    "x_train4 = x_train4.astype('float')\n",
    "y_train4 = y_train4.astype('int')\n",
    "x_test4 = x_train4.astype('float')\n",
    "y_test4 = y_train4.astype('int')\n",
    "print('FOLD 4 train feature shape:',x_train4.shape)\n",
    "print('FOLD 4 train output shape:',y_train4.shape)\n",
    "print('FOLD 4 test feature shape:',x_test4.shape)\n",
    "print('FOLD 4 test output shape:',y_test4.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ManwUNoLutDe"
   },
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lWPIWvzutDg",
    "outputId": "980a15a9-2cbe-4482-c731-004b899942a1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3c8aad69f294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mCV_rfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_rfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mCV_rfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters for Random forest 1: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCV_rfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train1' is not defined"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#FOLD1\n",
    "parameter_rfc1 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc1 = GridSearchCV(rfc, parameter_rfc1, cv = 5)\n",
    "CV_rfc1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for Random forest 1: \",CV_rfc1.best_params_)\n",
    "\n",
    "rfc1 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 20,\n",
    "                              n_estimators = 200)\n",
    "rfc1.fit(x_train1, y_train1)\n",
    "predrfc1 = rfc1.predict(x_test1)\n",
    "print(\"Test accuracy for Random Forest on FOLD 1: \",accuracy_score(y_test1,predrfc1))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_rfc2 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc2 = GridSearchCV(rfc, parameter_rfc2, cv = 5)\n",
    "CV_rfc2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for Random forest 2: \",CV_rfc2.best_params_)\n",
    "\n",
    "rfc2 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 200)\n",
    "rfc2.fit(x_train2, y_train2)\n",
    "predrfc2 = rfc2.predict(x_test2)\n",
    "print(\"Test accuracy for Random Forest on FOLD 2: \",accuracy_score(y_test2,predrfc2))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD3\n",
    "parameter_rfc3 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "\n",
    "CV_rfc3 = GridSearchCV(rfc, parameter_rfc3, cv = 5)\n",
    "CV_rfc3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for Random forest 3: \",CV_rfc3.best_params_)\n",
    "\n",
    "rfc3 = RandomForestClassifier(criterion = 'gini',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 10)\n",
    "rfc3.fit(x_train3, y_train3)\n",
    "predrfc3 = rfc3.predict(x_test3)\n",
    "print(\"Test accuracy for Random Forest on FOLD 3: \",accuracy_score(y_test3,predrfc3))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD4\n",
    "parameter_rfc4 = {'n_estimators':[10, 200], \n",
    "                   'criterion':('gini', 'entropy'),'max_depth':[1,20], \n",
    "                   'min_samples_split':[2,20], \n",
    "                   'min_samples_leaf':[1,20], \n",
    "                   'max_features':('auto','sqrt','log2'),\n",
    "                   'min_impurity_decrease':[0.0001,0.9999]}\n",
    "\n",
    "CV_rfc4 = GridSearchCV(rfc, parameter_rfc4, cv = 5)\n",
    "CV_rfc4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for Random forest 4: \",CV_rfc4.best_params_)\n",
    "\n",
    "rfc4 = RandomForestClassifier(criterion = 'entropy',\n",
    "                              max_depth = 20,\n",
    "                              max_features = 'auto',\n",
    "                              min_impurity_decrease = 0.0001,\n",
    "                              min_samples_leaf = 20,\n",
    "                              min_samples_split = 2,\n",
    "                              n_estimators = 200)\n",
    "rfc4.fit(x_train4, y_train4)\n",
    "predrfc4 = rfc4.predict(x_test4)\n",
    "print(\"Accuracy for Random Forest on FOLD 4: \",accuracy_score(y_test4,predrfc4))\n",
    "\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predrfc1),accuracy_score(y_test2,predrfc2), accuracy_score(y_test3,predrfc3), accuracy_score(y_test4,predrfc4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I73DX1ahutD1"
   },
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZ_wseVvutD6",
    "outputId": "e9a7200f-12fd-4fe6-dd1f-8b33de6f8979"
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "#FOLD1\n",
    "parameter_logistic1 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic1 = GridSearchCV(logistic, parameter_logistic1, cv = 5)\n",
    "CV_logistic1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for Logistic Regression 1: \", CV_logistic1.best_params_)\n",
    "\n",
    "logistic1 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic1.fit(x_train1, y_train1)\n",
    "predlog1 = logistic1.predict(x_test1)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 1: \",accuracy_score(y_test1,predlog1))\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_logistic2 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic2 = GridSearchCV(logistic, parameter_logistic2, cv = 5)\n",
    "CV_logistic2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for Logistic Regression 2: \", CV_logistic2.best_params_)\n",
    "\n",
    "logistic2 = LogisticRegression(C = 10, solver = 'sag', tol = 0.01)\n",
    "logistic2.fit(x_train2, y_train2)\n",
    "predlog2 = logistic2.predict(x_test2)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 2: \",accuracy_score(y_test2,predlog2))\n",
    "\n",
    "#FOLD3\n",
    "parameter_logistic3 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "\n",
    "CV_logistic3 = GridSearchCV(logistic, parameter_logistic3, cv = 5)\n",
    "CV_logistic3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for Logistic Regression 3: \", CV_logistic3.best_params_)\n",
    "\n",
    "logistic3 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic3.fit(x_train3, y_train3)\n",
    "predlog3 = logistic3.predict(x_test3)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 3: \",accuracy_score(y_test3,predlog3))\n",
    "\n",
    "\n",
    "#FOLD4\n",
    "parameter_logistic4 = {'tol':[0.00001, 0.01], \n",
    "                       'C':[0.1, 10], \n",
    "                       'solver':('newton-cg', 'sag', 'lbfgs')}\n",
    "CV_logistic4 = GridSearchCV(logistic, parameter_logistic4, cv = 5)\n",
    "CV_logistic4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for Logistic Regression 4: \", CV_logistic4.best_params_)\n",
    "\n",
    "logistic4 = LogisticRegression(C = 10, solver = 'sag', tol= 0.01)\n",
    "logistic4.fit(x_train4, y_train4)\n",
    "predlog4 = logistic4.predict(x_test4)\n",
    "print(\"Accuracy for Logistic Regression on FOLD 4: \",accuracy_score(y_test4,predlog4))\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predlog1),accuracy_score(y_test2,predlog2), accuracy_score(y_test3,predlog3), accuracy_score(y_test4,predlog4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLFbZVqnutEF"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z4BHdc-utEH",
    "outputId": "67ef4572-dd75-4f2b-a58d-424c7e9523f8"
   },
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "\n",
    "#FOLD1\n",
    "parameter_svm1 = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), \n",
    "                  'C':[0.1, 10],\n",
    "                  'gamma':[0.01,0.9]}\n",
    "\n",
    "CV_svm1 = GridSearchCV(svm, parameter_svm1, cv = 2)\n",
    "CV_svm1.fit(x_train1, y_train1)\n",
    "print(\"Best parameters for SVM1: \", CV_svm1.best_params_)\n",
    "print(\"Best score for SVM1: \", CV_svm1.best_score_)\n",
    "\n",
    "svm1 = SVC(C = 0.1, kernel = 'rbf', gamma = 0.9, decision_function_shape = 'ovo')\n",
    "svm1.fit(x_train1, y_train1)\n",
    "predsvm1 = svm1.predict(x_test1)\n",
    "print(\"Accuracy for SVM on FOLD 1: \",accuracy_score(y_test1,predsvm1))\n",
    "\n",
    "\n",
    "\n",
    "#FOLD2\n",
    "parameter_svm2 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[0.1, 10]}\n",
    "\n",
    "CV_svm2 = GridSearchCV(svm, parameter_svm2, cv = 5)\n",
    "CV_svm2.fit(x_train2, y_train2)\n",
    "print(\"Best parameters for SVM2: \", CV_svm2.best_params_)\n",
    "\n",
    "svm2 = SVC(C = 10, kernel = 'linear')\n",
    "svm2.fit(x_train2, y_train2)\n",
    "predsvm2 = svm2.predict(x_test2)\n",
    "print(\"Accuracy for SVM on FOLD 2: \",accuracy_score(y_test2,predsvm2))\n",
    "\n",
    "#FOLD3\n",
    "parameter_svm3 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[1, 10]}\n",
    "\n",
    "CV_svm3 = GridSearchCV(svm, parameter_svm3, cv = 5)\n",
    "CV_svm3.fit(x_train3, y_train3)\n",
    "print(\"Best parameters for SVM3: \", CV_svm3.best_params_)\n",
    "\n",
    "svm3 = SVC(C = 1, kernel = 'linear')\n",
    "svm3.fit(x_train3, y_train3)\n",
    "predsvm3 = svm2.predict(x_test3)\n",
    "print(\"Accuracy for SVM on FOLD 3: \",accuracy_score(y_test3,predsvm3))\n",
    "\n",
    "#FOLD4\n",
    "parameter_svm4 = {'kernel':('linear', 'rbf', 'poly'), \n",
    "                  'C':[1, 10]}\n",
    "\n",
    "CV_svm4 = GridSearchCV(svm, parameter_svm4, cv = 5)\n",
    "CV_svm4.fit(x_train4, y_train4)\n",
    "print(\"Best parameters for SVM4: \", CV_svm4.best_params_)\n",
    "\n",
    "svm4 = SVC(C = 1, kernel = 'linear')\n",
    "svm4.fit(x_train4, y_train4)\n",
    "predsvm4 = svm4.predict(x_test4)\n",
    "print(\"Accuracy for SVM on FOLD 4: \",accuracy_score(y_test4,predsvm4))\n",
    "\n",
    "\n",
    "#AVERAGES\n",
    "score_test_array = np.array([accuracy_score(y_test1,predsvm1),accuracy_score(y_test2,predsvm2), accuracy_score(y_test3,predsvm3), accuracy_score(y_test4,predsvm4)])\n",
    "mean_score_test = np.mean(score_test_array) \n",
    "print('Average accuracy on test set:',mean_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLNjSlMrutEP"
   },
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xckIXHMWutER"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-19342f56ea83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                 'tol':[0.000001,0.01]}\n\u001b[1;32m      8\u001b[0m \u001b[0mNN1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mNN1_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mNN1_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_NN1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mNN1_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#FOLD1\n",
    "parameter_NN1 = {'hidden_layer_sizes':[1, 10],'activation':('identity', 'relu','logistic', 'tanh'),\n",
    "                 'solver':('lbfgs', 'sgd', 'adam'), 'alpha':[0.00001,0.01], 'batch_size':[10,100],\n",
    "                'learning_rate':('constant','invscaling','adaptive'), 'learning_rate_init':[0.00001,0.01],\n",
    "                'tol':[0.000001,0.01]}\n",
    "NN1_train = MLPClassifier()\n",
    "NN1_train.fit(x_train1, y_train1)\n",
    "NN1_valid = GridSearchCV(NN1_train, parameter_NN1)\n",
    "NN1_valid.fit(x_valid1, y_valid1)\n",
    "SVM1_valid.fit(x_train1, y_train1)\n",
    "print(NN1_valid.best_params_)\n",
    "NN1_score_train1 = NN1_train.score(x_train1, y_train1)\n",
    "NN1_score_valid1 = NN1_valid.score(x_valid1, y_valid1)\n",
    "NN1_score_test1 = NN1_valid.score(x_test1, y_test1)\n",
    "print('Accuracy on the training set 1: {:.3f}'.format(NN1_score_train1))\n",
    "print('Accuracy on the validation set 1: {:.3f}'.format(NN1_score_valid1))\n",
    "print('Accuracy on the test set 1: {:.3f}'.format(NN1_score_test1))\n",
    "print(NN1.predict(x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HN3pKGVxutEZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TRADING_v2_Selma.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
